{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ca432a-1fea-488f-a808-adc7e170be16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f2ff7-0b28-470d-a38d-9326cdc4b9e3",
   "metadata": {},
   "source": [
    "In this jupyter notebook the necessary code to run the experiments will be found. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e71c20-b22a-4a57-8016-f3ba2a050a29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e997e6b-7002-4d1a-b9f5-72204930e9d2",
   "metadata": {},
   "source": [
    "The code snippet provided sets up the environment by installing matplotlib for data visualization and scapy for packet crafting and network traffic analysis. It imports various Python libraries such as ast for processing tree-based data structures, ipaddress for handling IPv4 addresses and networks, and json for manipulating JSON data formats. The script also utilizes matplotlib for plotting and pandas for data handling to create visual representations of network data. Notably, it includes custom modules like EPHeader and MRI, presumably for enhanced packet header manipulation and Magnetic Resonance Imaging data processing within network packets, respectively. The code also initializes the fablib_manager from the fabrictestbed_extensions library, which likely facilitates interaction with a fabric testbed environment, enabling hands-on experiments with virtual network configurations and behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02668b67-f809-4a10-ab35-ba7631e348dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip3 install scapy\n",
    "\n",
    "import ast\n",
    "import ipaddress\n",
    "import json\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "from io import StringIO\n",
    "from ipaddress import IPv4Address, IPv4Network\n",
    "from scapy.all import *\n",
    "from time import sleep\n",
    "from utils.EPHeader import *\n",
    "from utils.MRI import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed71213f-86ac-4c92-bd81-7f7650708d4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Variables, nodes and interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f992e-3c4e-4b4f-8ceb-82a9f8884101",
   "metadata": {},
   "source": [
    "This Python code manages network configurations within a specified network slice named \"INT\" using the fablib library. It reads from a JSON file to retrieve MAC and IP addresses for various hosts and switches across different subnets. The script defines network parameters, including expanding subnet masks for broader network coverage. It identifies network devices and their interfaces, facilitating detailed management of connections between hosts and switches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920463f-0bf9-4a62-a610-24b825d1cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 0\n",
    "slice_name = \"INT\"  # Slice name\n",
    "\n",
    "fablib = fablib_manager()\n",
    "slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "file_path = './utils/network_data.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    # MAC\n",
    "    h1_mac = data['hosts']['h1']['mac']\n",
    "    h2_mac = data['hosts']['h2']['mac']\n",
    "    h3_mac = data['hosts']['h3']['mac']\n",
    "    h4_mac = data['hosts']['h4']['mac']\n",
    "\n",
    "    s1_mac_1 = data['switches']['s1']['macs'][0]\n",
    "    s1_mac_2 = data['switches']['s1']['macs'][1]\n",
    "    s1_mac_3 = data['switches']['s1']['macs'][2]\n",
    "    s1_mac_4 = data['switches']['s1']['macs'][3]\n",
    "\n",
    "    s2_mac_1 = data['switches']['s2']['macs'][0]\n",
    "    s2_mac_2 = data['switches']['s2']['macs'][1]\n",
    "    s2_mac_3 = data['switches']['s2']['macs'][2]\n",
    "    s2_mac_4 = data['switches']['s2']['macs'][3]\n",
    "\n",
    "    s3_mac_1 = data['switches']['s3']['macs'][0]\n",
    "    s3_mac_2 = data['switches']['s3']['macs'][1]\n",
    "    s3_mac_3 = data['switches']['s3']['macs'][2]\n",
    "    s3_mac_4 = data['switches']['s3']['macs'][3]\n",
    "\n",
    "    s4_mac_1 = data['switches']['s4']['macs'][0]\n",
    "    s4_mac_2 = data['switches']['s4']['macs'][1]\n",
    "    s4_mac_3 = data['switches']['s4']['macs'][2]\n",
    "    s4_mac_4 = data['switches']['s4']['macs'][3]\n",
    "\n",
    "    # IP\n",
    "    subnet1 = data['subnets']['subnet1']\n",
    "    h1_ip = data['hosts']['h1']['ip']\n",
    "    s1_ip = data['switches']['s1']['ip']\n",
    "\n",
    "    subnet2 = data['subnets']['subnet2']\n",
    "    h2_ip = data['hosts']['h2']['ip']\n",
    "    s2_ip = data['switches']['s2']['ip']\n",
    "    \n",
    "    subnet3 = data['subnets']['subnet3']\n",
    "    h3_ip = data['hosts']['h3']['ip']\n",
    "    s3_ip = data['switches']['s3']['ip']\n",
    "    \n",
    "    subnet4 = data['subnets']['subnet4']\n",
    "    h4_ip = data['hosts']['h4']['ip']\n",
    "    s4_ip = data['switches']['s4']['ip']\n",
    "\n",
    "network = ipaddress.IPv4Network(subnet1)\n",
    "net = network.supernet(new_prefix=16)\n",
    "\n",
    "s1 = slice.get_node(name='s1')\n",
    "s2 = slice.get_node(name='s2')\n",
    "s3 = slice.get_node(name='s3')\n",
    "s4 = slice.get_node(name='s4')\n",
    "\n",
    "h1 = slice.get_node(name='h1')\n",
    "h2 = slice.get_node(name='h2')\n",
    "h3 = slice.get_node(name='h3')\n",
    "h4 = slice.get_node(name='h4')\n",
    "\n",
    "s1_iface1_name = s1.get_interface(network_name='s1h1').get_device_name()\n",
    "s1_iface2_name = s1.get_interface(network_name='s1s2').get_device_name()\n",
    "s1_iface3_name = s1.get_interface(network_name='s1s3').get_device_name()\n",
    "s1_iface4_name = s1.get_interface(network_name='s1s4').get_device_name()\n",
    "s2_iface1_name = s2.get_interface(network_name='s1s2').get_device_name()\n",
    "s2_iface2_name = s2.get_interface(network_name='s2h2').get_device_name()\n",
    "s2_iface3_name = s2.get_interface(network_name='s2s3').get_device_name()\n",
    "s2_iface4_name = s2.get_interface(network_name='s2s4').get_device_name()\n",
    "s3_iface1_name = s3.get_interface(network_name='s1s3').get_device_name()\n",
    "s3_iface2_name = s3.get_interface(network_name='s2s3').get_device_name()\n",
    "s3_iface3_name = s3.get_interface(network_name='s3h3').get_device_name()\n",
    "s3_iface4_name = s3.get_interface(network_name='s3s4').get_device_name()\n",
    "s4_iface1_name = s4.get_interface(network_name='s1s4').get_device_name()\n",
    "s4_iface2_name = s4.get_interface(network_name='s2s4').get_device_name()\n",
    "s4_iface3_name = s4.get_interface(network_name='s3s4').get_device_name()\n",
    "s4_iface4_name = s4.get_interface(network_name='s4h4').get_device_name()\n",
    "h1_iface0_name = h1.get_interface(network_name='s1h1').get_device_name()\n",
    "h2_iface0_name = h2.get_interface(network_name='s2h2').get_device_name()\n",
    "h3_iface0_name = h3.get_interface(network_name='s3h3').get_device_name()\n",
    "h4_iface0_name = h4.get_interface(network_name='s4h4').get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d4f2d-3ef6-4adb-a3ca-34f0af8486fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = s1.execute(\"sudo apt install -y python3-pip\", quiet=True)\n",
    "print(\"s1\")\n",
    "stdout, stderr = s2.execute(\"sudo apt install -y python3-pip\", quiet=True)\n",
    "print(\"s2\")\n",
    "stdout, stderr = h1.execute(\"sudo apt install -y python3-pip\", quiet=True)\n",
    "print(\"h1\")\n",
    "stdout, stderr = h2.execute(\"sudo apt install -y python3-pip\", quiet=True)\n",
    "print(\"h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d950a-abcc-452f-b383-261d2d42faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = s1.execute(\"sudo pip3 install pandas\", quiet=True)\n",
    "print(\"s1\")\n",
    "stdout, stderr = s2.execute(\"sudo pip3 install pandas\", quiet=True)\n",
    "print(\"s2\")\n",
    "stdout, stderr = h1.execute(\"sudo pip3 install pandas\", quiet=True)\n",
    "print(\"h1\")\n",
    "stdout, stderr = h2.execute(\"sudo pip3 install pandas\", quiet=True)\n",
    "print(\"h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0314c-9354-49b2-9f33-b5bd40150161",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = h1.execute(\"sudo apt install -y iperf3\", quiet=True)\n",
    "print(\"h1\")\n",
    "stdout, stderr = h2.execute(\"sudo apt install -y iperf3\", quiet=True)\n",
    "print(\"h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120024a7-fd4d-4b79-a064-4d521030496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = h1.execute(\"sudo apt-get update\", quiet=True)\n",
    "stdout, stderr = h1.execute(\"sudo apt-get install ntp\", quiet=True)\n",
    "stdout, stderr = h1.execute(\"sudo systemctl restart ntp\", quiet=True)\n",
    "\n",
    "stdout, stderr = h2.execute(\"sudo apt-get update\", quiet=True)\n",
    "stdout, stderr = h2.execute(\"sudo apt-get install ntp\", quiet=True)\n",
    "stdout, stderr = h2.execute(\"sudo systemctl restart ntp\", quiet=True)\n",
    "\n",
    "stdout, stderr = s1.execute(\"sudo apt-get update\", quiet=True)\n",
    "stdout, stderr = s1.execute(\"sudo apt-get install ntp\", quiet=True)\n",
    "stdout, stderr = s1.execute(\"sudo systemctl restart ntp\", quiet=True)\n",
    "\n",
    "stdout, stderr = s2.execute(\"sudo apt-get update\", quiet=True)\n",
    "stdout, stderr = s2.execute(\"sudo apt-get install ntp\", quiet=True)\n",
    "stdout, stderr = s2.execute(\"sudo systemctl restart ntp\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6f61e0-f5c5-4d64-95e6-02ef6a9c295b",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d3e70d-5081-4846-9b19-ef93be74ed26",
   "metadata": {},
   "source": [
    "The code used in each of the experiments is outlined below. Initially, the necessary files will be transferred to the nodes. Once the files are in place, the experiment can commence. The experiment involves three main steps:\n",
    "\n",
    "- Data Collection: Execute specific files to gather initial information from the nodes.\n",
    "- Traffic Generation: Launch the corresponding network traffic based on the experiment's requirements.\n",
    "- Data Processing and Storage: Process the extracted data from the configuration files and save the results in CSV format.\n",
    "  \n",
    "By following these steps, we ensure a structured approach to conducting the experiments, capturing relevant data, and organizing the results for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50ebce-45ef-446c-bfe7-58ed5f3db48b",
   "metadata": {},
   "source": [
    "### Upload packets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3ef7c3-0b6d-48f8-83ef-9e5bf3c1dffc",
   "metadata": {},
   "source": [
    "This Python code imports the Uploader class from a module named utils.uploader and creates an instance of the Uploader class, assigning it to the variable up. This instance can now be used to upload the file (second argument) to the node (first argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d4896a-e6e4-4fec-9cfa-7a3067f0bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.uploader import Uploader\n",
    "up = Uploader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a50871-77b4-4b5f-88c5-3883a9d32a2f",
   "metadata": {},
   "source": [
    "In the following code we are going to upload to each one of the nodes a python script called \"nPackets.py\". This Python script utilizes the Scapy library to analyze packet capture files (.pcap) for network diagnostics. It reads a specified pcap file and extracts packets based on specific protocols—UDP and a custom protocol indicated by TYPE_EPHeader. For each protocol type, the script computes statistics such as the total number of packets, minimum, average, and maximum packet sizes. These statistics are generated for both UDP packets and packets matching the custom protocol, providing insight into the traffic characteristics of each. The script is designed for command-line execution with the pcap file path as an argument, making it suitable for automated network analysis tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff43bf3a-9037-48b7-8913-e956edb17641",
   "metadata": {},
   "outputs": [],
   "source": [
    "up.upload(\"h1\", \"./graphs/nPackets.py\")\n",
    "up.upload(\"h2\", \"./graphs/nPackets.py\")\n",
    "up.upload(\"s1\", \"./graphs/nPackets.py\")\n",
    "up.upload(\"s2\", \"./graphs/nPackets.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485dab36-b227-4f54-ba90-366f47a97d21",
   "metadata": {},
   "source": [
    "In the following code we are going to upload to \"h1\" a python script called \"BgT_iperf.py\".The Python script serves as a command-line tool to facilitate network performance testing using the iperf3 utility in client mode with UDP packets. It accepts three parameters: the destination server address, the test duration in seconds, and the number of parallel client threads, all of which are managed through argparse for command-line integration. The script constructs an iperf3 command with these parameters and executes it, capturing the output in JSON format for detailed performance analysis. This output is then printed to the console, and the script ensures the buffer is flushed immediately for real-time result viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801115f-d307-4ff8-8406-fab4ba3abb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "up.upload(\"h1\", \"./graphs/BgT_iperf.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf8c954-e839-4238-abca-d2489c5a7216",
   "metadata": {},
   "source": [
    "In the following code we are going to upload to \"h2\" a python script called \"receive.py\".The Python script uses the Scapy library to monitor and analyze network packets tailored to a custom protocol. It selects a network interface, specifically looking for \"enp7s0\", and defines custom packet structures, including `EPHeader` and `SwitchTrace`, to handle specialized network data. The script captures packets on the specified interface that contain a unique protocol identifier, converting captured packets to hexadecimal for analysis and logging them to a pcap file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033aa16-8df8-47fa-b9ba-11bed496d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "up.upload(\"h2\", \"./graphs/receive.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e616a1-9ed4-4d08-b3c2-1bb7d3e8b784",
   "metadata": {},
   "source": [
    "In the following code we are going to upload to \"h1\" a python script called \"sendPackets.py\". This Python script leverages the Scapy library to create and transmit custom network packets for testing purposes. The script constructs packets comprising Ethernet and IP layers, including a specialized EPHeader and an IPOption_MRI for multipath routing information. Each packet is populated with predefined values and sent in a loop based on user input, with a one-second delay between transmissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a85d7-3f94-480b-9e1a-f471a0a5bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "up.upload(\"h1\", \"./graphs/sendPacket.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f0f86-ea0c-4164-b078-46904443cbc8",
   "metadata": {},
   "source": [
    "### Start experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e8e9a8-5493-42fa-a302-14ee3f380963",
   "metadata": {},
   "source": [
    "The first line executes a command to terminate all iperf3 processes silently in h2, while the second line does the same for all Python 3 instances, capturing any output or errors into stdout and stderr respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9323fb-48f3-471b-8487-963212724d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2.execute(\"sudo killall iperf3\", quiet=True)\n",
    "stdout, stderr = h2.execute(\"sudo killall python3\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5bafb5-dba6-4fb5-b0c9-e907667e1307",
   "metadata": {},
   "source": [
    "The Python code snippet launches an iperf3 server instance on \"h2\" in a separate thread. This is accomplished using a method called execute_thread, which likely allows the iperf3 -s command (indicating server mode) to run asynchronously, ensuring that the main program can continue executing other tasks without waiting for the iperf3 server process to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d61fc-702c-4515-8e71-533a2ec6c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "iperf2 = h2.execute_thread(f\"iperf3 -s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef298c97-d3de-4bb4-a3cf-961d49af5bf3",
   "metadata": {},
   "source": [
    "In the code snippet, three variables are set up for a configuration or script that appears to be preparing for a network performance testing scenario:\n",
    "\n",
    "- experimentNumber: This variable likely indicates a identifier for the experiment.\n",
    "\n",
    "- tiperf: This variable specifies the duration in seconds for the iperf3 command. \n",
    "\n",
    "- nthreads: This variable defines the number of parallel client threads to be used in the test. \n",
    "\n",
    "These variables are essential for controlling the parameters of a network testing session, allowing for precise adjustments to the testing environment based on the needs of the experiment or the specifics of the network being tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a9830-a657-4c35-a511-86e93f5c8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentNumber = 28\n",
    "tiperf = 10\n",
    "nthreads = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece78cff-b467-4c18-b9fc-6d255b30697e",
   "metadata": {},
   "source": [
    "The Python code snippet launches a script named receive.py on \"h2\" using elevated privileges (sudo). The script is run asynchronously in a separate thread by the method execute_thread, allowing the main program to continue its execution without waiting for receive.py to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b1a40-61ac-47a7-aba1-810205b54735",
   "metadata": {},
   "outputs": [],
   "source": [
    "mriPacket_receive = h2.execute_thread(f\"sudo python3 receive.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0b6f72-57d7-4573-8ac1-c4ed499dcd78",
   "metadata": {},
   "source": [
    "The following cell orchestrates parallel network traffic captures across multiple devices—two hosts and two switches—using `tcpdump`, a command-line packet analyzer. Commands are executed asynchronously in separate threads to prevent blocking, enabling simultaneous captures on specified network interfaces for each device. For hosts `h1` and `h2`, and switches `s1` and `s2`, traffic is recorded on their respective interfaces, with each session outputting to a dedicated pcap file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e01e4-c004-40e4-8e85-46a0ee233f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1.execute_thread(f\"sudo tcpdump -i {h1_iface0_name} -w h1_0.pcap\")\n",
    "h2.execute_thread(f\"sudo tcpdump -i {h2_iface0_name} -w h2_0.pcap\")\n",
    "print(\"hosts\")\n",
    "s1.execute_thread(f\"sudo tcpdump -i {s1_iface1_name} -w s1_1.pcap\")\n",
    "s1.execute_thread(f\"sudo tcpdump -i {s1_iface2_name} -w s1_2.pcap\")\n",
    "print(\"s1\")\n",
    "s2.execute_thread(f\"sudo tcpdump -i {s2_iface1_name} -w s2_1.pcap\")\n",
    "s2.execute_thread(f\"sudo tcpdump -i {s2_iface2_name} -w s2_2.pcap\")\n",
    "print(\"s2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7117c8-b695-4a6d-9102-a1b8462a7e84",
   "metadata": {},
   "source": [
    "The code snippet initiates an asynchronous task on the host \"h1\" to execute a Python script named \"sendPacket.py\" using elevated privileges (`sudo`). This script send packets by passing three arguments: `1`, `2`, and `30`. The first one is represents the host that is sending the packet. The second argument, in this case \"2\", is the host destination. And the last argument represents the number of packes that are going to send."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103f927-6a92-4d91-bdda-6cd44a87462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mriPacket_send = h1.execute_thread(f\"sudo python3 sendPacket.py 1 2 30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4198c2a-0de0-4229-90bd-682ed45b10b9",
   "metadata": {},
   "source": [
    "The sleep(10) function call in your code causes the program to pause or delay its execution for 10 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74171cb6-8957-4a8f-b56f-8375ed3282bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65605ccb-09d2-413a-be6e-71e3ab650ac8",
   "metadata": {},
   "source": [
    "The Python code snippet runs a script named \"BgT_iperf.py\" on the host \"h1\", passing three arguments: h2_ip, tiperf, and nthreads. \"h2_ip\" represents the ip of the destination host. \"tiperf\" id the duration of the test in seconds, specified by the tiperf variable. Finally \"nthreads\" is the number of parallel client threads to use during the iperf test, specified by the nthreads variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d4a8fa-dc05-427f-b3fd-0599ce3049d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iperf_h1 = h1.execute(f\"python3 BgT_iperf.py {h2_ip} {tiperf} {nthreads}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf12c7bb-cef9-443e-acfc-fbad2e421ebd",
   "metadata": {},
   "source": [
    "The sleep(10) function call in your code causes the program to pause or delay its execution for 10 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1921a6-b699-4140-a4a9-a6f56fee8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db4786-c794-4dfa-9f53-dbe774e75dc5",
   "metadata": {},
   "source": [
    "The code snippet processes the JSON output from an iperf network test, formats it for readability, and saves it to a file. It begins by parsing the JSON output stored in iperf_h1[0] into a Python dictionary. Then, it converts this dictionary back into a JSON-formatted string with indentation for clarity. Finally, it writes this formatted JSON data to a file named according to the experiment number, ensuring the results are neatly saved and organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73276184-803c-48d8-86d4-027d5af763c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = json.loads(iperf_h1[0])\n",
    "json_data = json.dumps(data_dict, indent=4)\n",
    "with open(f'./graphs/iperf/exp{experimentNumber}.json', 'w') as file:\n",
    "    file.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f52376-e78a-41fa-8e97-e9f89936b8f8",
   "metadata": {},
   "source": [
    "The code snippet processes the output of the receive.py program, formats it for readability, and saves it to a file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481bd0d-5a50-491e-a8e4-880955bdda61",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = h2.execute(\"sudo killall python3\", quiet=True)\n",
    "hex_list = mriPacket_receive.result()[0].split('\\n')[1:-1]\n",
    "df = pd.DataFrame(hex_list, columns=['Values'])\n",
    "df.to_csv(f'./graphs/iperf/exp{experimentNumber}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458609f9-53b4-4f53-bd2e-35abf5eec101",
   "metadata": {},
   "source": [
    "The following lines executes a command to terminate all tcpdump processes silently in all the nodes of the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41212524-353f-46d7-80c1-433c3347414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = h1.execute(\"sudo killall tcpdump\", quiet=True)\n",
    "stdout, stderr = h2.execute(\"sudo killall tcpdump\", quiet=True)\n",
    "stdout, stderr = s1.execute(\"sudo killall tcpdump\", quiet=True)\n",
    "stdout, stderr = s2.execute(\"sudo killall tcpdump\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773c1ee-75a9-4c3b-9678-4eaee90108fe",
   "metadata": {},
   "source": [
    "The following code process the pcap output of each of the tcpdump commands and extract the values of the number of packets of each type and the size of bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6223c26-79a7-4297-ba28-e6886aed0d2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h1_0 = h1.execute(\"sudo python3 nPackets.py h1_0.pcap\")\n",
    "h2_0 = h2.execute(\"sudo python3 nPackets.py h2_0.pcap\")\n",
    "print(\"hosts\")\n",
    "s1_1 = s1.execute(\"sudo python3 nPackets.py s1_1.pcap\")\n",
    "s1_2 = s1.execute(\"sudo python3 nPackets.py s1_2.pcap\")\n",
    "print(\"s1\")\n",
    "s2_1 = s2.execute(\"sudo python3 nPackets.py s2_1.pcap\")\n",
    "s2_2 = s2.execute(\"sudo python3 nPackets.py s2_2.pcap\")\n",
    "print(\"s2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20367768-cbde-4876-90c8-ece7dbea8e37",
   "metadata": {},
   "source": [
    "In the following code we are going to take the outputs of the cell above and store them in a pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502534b-09a0-4f29-af10-6adcab20a78a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "array_string = h1_0[0].strip()\n",
    "data = json.loads(array_string)\n",
    "dataframeh1_0 = pd.DataFrame(data).T\n",
    "dataframeh1_0.columns = ['h1_MRI', 'h1_iperf']\n",
    "\n",
    "array_string = h2_0[0].strip()\n",
    "data = json.loads(array_string)\n",
    "dataframeh2_0 = pd.DataFrame(data).T\n",
    "dataframeh2_0.columns = ['h2_MRI', 'h2_iperf']\n",
    "\n",
    "dataframe_hosts = pd.concat([dataframeh1_0, dataframeh2_0], axis=1)\n",
    "\n",
    "array_string = s1_1[0].strip()\n",
    "data = json.loads(array_string)\n",
    "dataframes1_1 = pd.DataFrame(data).T\n",
    "dataframes1_1.columns = ['s11_MRI', 's11_iperf']\n",
    "\n",
    "array_string = s1_2[0].strip()\n",
    "data = json.loads(array_string)\n",
    "dataframes1_2 = pd.DataFrame(data).T\n",
    "dataframes1_2.columns = ['s12_MRI', 's12_iperf']\n",
    "\n",
    "dataframe_s1 = pd.concat([dataframes1_1, dataframes1_2], axis=1)\n",
    "\n",
    "array_string = s2_1[0].strip()\n",
    "data = json.loads(array_string)\n",
    "dataframes2_1 = pd.DataFrame(data).T\n",
    "dataframes2_1.columns = ['s21_MRI', 's21_iperf']\n",
    "\n",
    "array_string = s2_2[0].strip()\n",
    "data = json.loads(array_string)\n",
    "dataframes2_2 = pd.DataFrame(data).T\n",
    "dataframes2_2.columns = ['s22_MRI', 's22_iperf']\n",
    "\n",
    "dataframe_s2 = pd.concat([dataframes2_1, dataframes2_2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfd6e97-ad20-45ac-b9a3-ef8ecc9ffe60",
   "metadata": {},
   "source": [
    "The code snippet saves data from three different DataFrames to CSV files, organizing the results of an experiment based on the experimentNumber variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab9912-e65a-4a32-8dbf-63bdbeab87b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_hosts.to_csv(f'./graphs/iperf/exp{experimentNumber}_nH.csv', index=False)\n",
    "dataframe_s1.to_csv(f'./graphs/iperf/exp{experimentNumber}_nS1.csv', index=False)\n",
    "dataframe_s2.to_csv(f'./graphs/iperf/exp{experimentNumber}_nS2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
